ğŸ± Cat Emotion Detector

Developed by: Abdalrhman Badawi & Ziad Sakr
Base Model: ResNet50
Experiment Tracking: MLflow

ğŸ“˜ Project Overview

This project aims to classify cat emotions using deep learning on image data.
The model can identify nine emotional states:

angry, disgusted, happy, normal, relaxed, sad, scared, surprised, uncomfortable

The model was trained using a ResNet50 backbone, fine-tuned on a custom dataset of labeled cat facial expressions.
All experiments, metrics, and evaluation reports were logged using MLflow for full reproducibility.

ğŸ§± Project Structure
Catto-Lingo/
â””â”€â”€ cat-emotion-detector/
    â”œâ”€â”€ data/                   # Dataset or DVC tracking files
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ preprocess/         # Data loading and augmentations
    â”‚   â”œâ”€â”€ models/             # Model architectures (ResNet, etc.)
    â”‚   â”œâ”€â”€ train.py            # Training loop
    â”‚   â”œâ”€â”€ evaluate.py         # Model evaluation and metrics
    â”‚   â””â”€â”€ utils.py            # Helper functions
    â”œâ”€â”€ notebooks/              # Optional Jupyter notebooks
    â”œâ”€â”€ results/
    â”‚   â”œâ”€â”€ confusion_matrix.png
    â”‚   â”œâ”€â”€ metrics.csv
    â”‚   â””â”€â”€ model_report.txt
    â”œâ”€â”€ requirements.txt        # Dependencies
    â”œâ”€â”€ main.py                 # Entry point (training + evaluation)
    â”œâ”€â”€ README.md               # Documentation
    â””â”€â”€ .gitignore

âš™ï¸ Setup & Installation

Clone the repository:

git clone https://github.com/NOUR-wq277/Catto-Lingo.git
cd Catto-Lingo/cat-emotion-detector


Install dependencies:

pip install -r requirements.txt


(Optional) Configure MLflow tracking URI in main.py:

mlflow.set_tracking_uri("file:./mlruns")

ğŸš€ Training

To train the model and log results in MLflow:

python main.py --mode train


You can customize:

--epochs â†’ number of epochs

--batch_size â†’ training batch size

--lr â†’ learning rate

Example:

python main.py --mode train --epochs 30 --batch_size 16 --lr 0.0001

ğŸ“Š Evaluation

To evaluate a trained model and view metrics:

python main.py --mode test


Then open MLflow UI to visualize results:

mlflow ui


Open the local MLflow dashboard at: http://localhost:5000

ğŸ“ˆ Results Summary
Metric	Value
Accuracy	0.8915
Macro F1-Score	0.8406
Dataset Size	1051 test images

Key observations:

The model performs consistently well across most classes.

Some underrepresented emotions (like no clear emotion) show slightly lower F1 scores.

Further tuning or data balancing can improve performance.

ğŸ§  Future Improvements

Integrate Grad-CAM visualization to explain predictions.

Use EfficientNet for potentially higher accuracy.

Balance emotion classes with augmentation or synthetic data.

ğŸ Acknowledgments

This project was developed as part of a research/training effort on visual emotion recognition for animals.
Special thanks to mentors and collaborators who supported the work.
